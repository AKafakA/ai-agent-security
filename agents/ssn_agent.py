import fire
from langchain.agents import AgentExecutor
from langchain.agents.format_scratchpad.openai_tools import (
    format_to_openai_tool_messages,
)
from langchain.agents.output_parsers.openai_tools import OpenAIToolsAgentOutputParser
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables.base import Runnable
from langchain_core.tools import StructuredTool
from langchain_openai import ChatOpenAI
from langchain.pydantic_v1 import BaseModel, Field
import pyffx
import re
import sys

from agents.chains import create_tool_selection_chain, create_request_handling_chain


def encrypt_ssn(
    secret_key: str,
    ssn: str,
) -> str:
    """
    Encrypts SSNs based on secret key

        Args:
            secret_key (str): Secret key
            ssn (str): SSN to encrypt

        Returns:
            (str): Encrypted ciphertext of SSN
    """
    e = pyffx.Integer(secret_key, length=1)
    return "".join([str(e.encrypt(int(d))) for d in ssn])


def decrypt_ssn(
    secret_key: str,
    ssn_ciphertext: str,
) -> str:
    """
    Decrypts SSN ciphertexts based on secret key

        Args:
            secret_key (str): Secret key
            ssn_ciphertext (str): Encrypted SSN ciphertext to decrypt

        Returns:
            (str): Original SSN
    """
    e = pyffx.Integer(secret_key, length=1)
    return "".join([str(e.decrypt(int(d))) for d in ssn_ciphertext])


def post_process(result: str, user_id: int) -> str:
    """
    Postprocesses output from LLM returned after agent execution by looking for any numbers and decrypting them

        Args:
            result (str): Output from LLM
            user_id (int): User ID used to retrieve secret key

        Returns:
            (str): Output from LLM but with numbers replaced by their digit-by-digit decryption
    """
    nums = re.findall(r"\d+", result)
    for num in nums:
        # Decrypt using user's secret key
        result = result.replace(num, decrypt_ssn(secretkeys[user_id], num))
    return result


### Private data setup ###
secretkeys = [
    b"SH7SJ91LP0900",
    b"JF328NOSI38",
    b"JS8372IOS00SUD",
    b"SDH823JSHDQWIR93",
]
secretkey_to_ssn = {
    b"SH7SJ91LP0900": "754345435",
    b"JF328NOSI38": "382744372",
    b"JS8372IOS00SUD": "192384753",
    b"SDH823JSHDQWIR93": "473243729",
}
ciphertexts = []
for key, value in secretkey_to_ssn.items():
    ciphertexts.append(encrypt_ssn(key, value))


def get_number(user_id: int) -> str:
    """Gets the encrypted ciphertext of the user's SSN"""
    return ciphertexts[user_id]


def run_llama2_agent(user_query: str, user_id: int) -> str:
    """
    Runs an agent using Llama2 as the LLM

        Args:
            user_query (str): User input to respond to
            user_id (int): User ID used to retrieve SSN if agent deems it necessary

        Returns:
            (str): Response generated by agent
    """
    # Decide on what tool to use
    tool_selector_chain = create_tool_selection_chain()
    tool = tool_selector_chain.invoke({"input": user_query})
    print("Selected tool: " + tool)
    # Make sure that the correct tool is picked
    if tool != "get_number":
        sys.exit("Wrong tool")
    else:
        ciphertext = get_number(user_id)
    # Fulfill user request
    request_handling_chain = create_request_handling_chain()
    result = request_handling_chain.invoke(
        {"input": user_query, "ciphertext": ciphertext}
    )
    print("Initial agent output: " + result)
    return result


### Tools ###
class ReturnNumberInput(BaseModel):
    user_id: int = Field(description="user id number")


# Tool for returning SSN ciphertext to agent
return_number = StructuredTool.from_function(
    func=get_number,
    name="return_number",
    description="""Gets randomly-generated numbers""",
    args_schema=ReturnNumberInput,
)


class DummyToolInput(BaseModel):
    x: int = Field(description="number")


dummy_tool = StructuredTool.from_function(
    func=lambda x: x,
    name="dummy_tool",
    description="""Dummy tool""",
    args_schema=DummyToolInput,
)


class AddNumbersInput(BaseModel):
    x: int = Field(description="First number to add")
    y: int = Field(description="Second number to add")


add_numbers = StructuredTool.from_function(
    func=lambda x, y: x + y,
    name="add_numbers",
    description="""Adds two numbers together and returns the result""",
    args_schema=AddNumbersInput,
)

tools = [return_number, dummy_tool, add_numbers]  # List of tools


def create_agent() -> Runnable:
    """Creates a GPT-3.5-turbo agent runnable with access to the list of tools defined above"""
    # Need to set OPENAI_API_KEY environment variable <export OPENAI_API_KEY="key">
    llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)
    llm_with_tools = llm.bind_tools(tools)

    template_query = """Based on the user id below, return a response to the user's question:
    User ID: {user_id}
    Question: {question}
    """
    prompt_template = ChatPromptTemplate.from_messages(
        [
            (
                "system",
                "You are a lab assistant that returns made-up numbers to lab workers.",
            ),
            ("human", template_query),
            MessagesPlaceholder(variable_name="agent_scratchpad"),
        ]
    )

    agent = (
        {
            "question": lambda x: x["question"],
            "user_id": lambda x: x["user_id"],
            "agent_scratchpad": lambda x: format_to_openai_tool_messages(
                x["intermediate_steps"]
            ),
        }
        | prompt_template
        | llm_with_tools
        | OpenAIToolsAgentOutputParser()
    )
    return agent


def run_chatgpt_agent(user_query: str, user_id: int) -> str:
    """
    Runs an agent using gpt-3.5-turbo as the LLM

        Args:
            user_query (str): User input to respond to
            user_id (int): User ID used to retrieve SSN if agent deems it necessary

        Returns:
            (str): Response generated by agent
    """
    agent_executor = AgentExecutor(agent=create_agent(), tools=tools, verbose=True)
    result = agent_executor.invoke({"question": user_query, "user_id": user_id})
    return result["output"]


agents = {"chatgpt": run_chatgpt_agent, "llama2": run_llama2_agent}


def main(agent: str = "chatgpt", user_id: int = 0):
    # User ID correlates to the index of the secret key in secretkeys, not really a user ID in essence
    if agent not in agents:
        sys.exit("Pick an agent from the following: [chatgpt, llama2]")
    # User prompt
    user_query = input("What would you like to do today?\n>>> ")
    # Run agent
    result = agents[agent](user_query, user_id)
    # Decrypt ciphertext
    post_processed_result = post_process(result, user_id)
    print("Postprocessed output: " + post_processed_result)
    print("Original SSN for comparison: " + secretkey_to_ssn[secretkeys[user_id]])


if __name__ == "__main__":
    fire.Fire(main)
